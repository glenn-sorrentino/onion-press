Even when our private data doesn’t get sent directly to tech companies, our devices still record our every move locally. Can you name every single web page you visited last month? Your web browser probably can, and so can web trackers that follow your activity across the internet.

In addition to the constant background surveillance that everyone faces, workers with access to sensitive datasets are often under even stricter corporate or government surveillance. Their work computers and phones come preinstalled with spyware that monitors everything the employees do. Database systems keep track of exactly who searches for exactly which search terms and when, and which documents they open, download, or print.

It’s in this environment that ordinary people find themselves becoming sources. Through the course of their work they witness something unethical or disturbing. They might make a folder with incriminating documents, or take some screenshots of the company chat, or do some searches on internal databases to learn more and make sure their suspicions are correct. They might email themselves some documents, or copy files to a USB stick that they plug into their work computer. They might text their friends or family for advice while thinking about what to do next. Most sources aren’t aware of the massive digital trail that they’ve already left by the time they reach out to a journalist or regulator.

In this chapter, you’ll learn about protecting sources and securing the datasets you obtain from them. I’ll go over the editorial and ethical considerations involved in redacting documents and deciding what information to publish, as well as where you should store datasets based on how sensitive they are. I’ll show how to verify that datasets are authentic, describing how I’ve done so in the past for hacked data from COVID-19 pandemic profiteers and chat logs from WikiLeaks. Verifying authenticity of datasets is not only important to writing accurate stories, it’s also critical to protecting your own reputation as a journalist. Finally, you’ll learn to use password managers and disk encryption and protect yourself from malicious documents.

### Safely Communicating with Sources

Because everything we do leaves a data trail, protecting sources is fraught. After you publish a blockbuster report based on information you’ve obtained from an anonymous whistleblower, you should expect the target of your investigation to launch an investigation of their own into your source’s identity. The balance of power between a confidential source and the leak investigators on their trail is extremely asymmetric. If you’re a journalist or researcher trying to protect your source, even doing all the right things perfectly isn’t always enough. Because so much of source protection is outside your control, it’s important to focus on the handful of things that are in your control.

In this section, I’ll describe which sources face risks and which don’t, as well as strategies for reducing that risk. I’ll also discuss the differences between working with confidential sources who have legitimate access to inside information and hackers who break the law to obtain information. It’s important for you to carefully consider how your own choices as an investigator could impact your source, preferably before you even begin speaking with one.

### Working with Public Data

Some datasets don’t have any risk to the source at all. When the government publishes a set of documents in response to a public records request, or is made public as part of a lawsuit, you can include as much of the data as you like in your report. This data might contain revelations that powerful people don’t want anyone to know, but you won’t put anyone at risk of retaliation when you bring attention to them, since the data is already public.
Similarly, you don’t need to worry about source protection for datasets that may contain sensitive data but are public and widely available, such as the BlueLeaks dataset you’ll download in Chapter 2. Any information you discover from that dataset has already been scoured by the FBI investigators trying to determine who the hacker was. In these cases, you don’t need to worry about how many people had access to the documents. There’s no chance of accidentally burning your source by giving too many details to a government or corporate media office when you ask if the data is real and if they have a statement. Since the dataset is already public, any damage to the source has already been done.

That said, if you’re dealing with a dataset from a confidential source—that is, a source that faces retaliation like getting fired, arrested, or even murdered if their identity is revealed—here’s what you need to keep in mind.

### Minimizing Your Digital Trail

Leave as small of a digital trail as you can when communicating with your source. Speak with them remotely as little as possible; that is, avoid talking over email, SMS messages, phone calls, direct messages in social media apps, and so on. Don’t follow your confidential source on social media, and they shouldn’t follow you. If you do have to send messages or make calls, use an encrypted messaging app like Signal, which I’ll cover in Chapter 2, and make sure your source deletes the records of their chats with you. You’ll often need to record what your source told you in order to report on it, but you should take steps to protect these records, such as removing them from messaging apps on your phone and keeping them locally on your computer rather than in a cloud service. If you no longer need your own records of conversations after you’ve published your report, such as for potential follow-up stories, delete them.

Make sure your source knows not to search the internet for you or for the reports that you publish in a way that could be associated with them. Google search history has been used as evidence against sources in the past. For example, in 2018, Treasury Department whistleblower Natalie Mayflower Sours Edwards was indicted for allegedly providing a secret dataset to BuzzFeed journalist Jason Leopold. The documents she was accused of leaking detailed suspicious financial transactions involving Republican Party operatives, senior members of Donald Trump’s 2020 election campaign, and a Kremlin-connected Russian agent and Russian oligarchs. During the leak investigation, the FBI got a search warrant to access her internet search history, and her indictment accused her of searching for multiple articles based on the contents of her alleged leaks shortly after they were published.

### Verifying Data

As a journalist or researcher, verifying that data you’ve obtained is authentic is one of your core responsibilities. The simplest way to authenticate documents is to ask the company or government that produced them if they’re real, but this is fraught with risk to your source. In some cases, you don’t want to give up any details that might reveal your source’s identity. I go into detail about ways to avoid this in the “Authenticating Datasets” section on page XX. You also might not want to even reveal that specific documents have been leaked. You’ll learn more about this in the “Redaction” section on page XX.

### Working with Hackers and Whistleblowers

The steps you must take to protect your source vary greatly depending on their technical sophistication. Not all sources are whistleblowers, people with inside access to datasets or documents who leak evidence of wrongdoing for ethical reasons. Sometimes your source may be a hacktivist who wants to bring down companies or government agencies that they find unjust.

Unlike most whistleblowers, hackers tend to understand that they’re under surveillance and that everything they do leaves a digital trail, so they usually take countermeasures to hide their tracks. It’s common for whistleblowers to reveal their identities to journalists for verification reasons, even if they aren’t publicly named, but hackers typically remain fully anonymous. However, hackers can often provide you with technical information you can use to independently authenticate a dataset using open source intelligence, which I describe in the “Authenticating Datasets” section on page XXX. As with any source, you can’t necessarily trust what hackers tell you, but their expertise can help you independently verify that the data they sent you is authentic. Because of all this, there’s often less risk to your source when publishing documents from hackers than from whistleblowers.

When communicating with a hacker source, it’s important that you stick to your role as a journalist or researcher. In the US, you’re not breaking any laws just by speaking with a source who’s a hacker, but your source is almost certainly breaking laws by hacking into companies or governments and stealing data. Don’t do anything that could be construed as conspiring with them. For example, don’t ask them to get specific data for you—let them give you whatever data they choose. If you’re a journalist working with an established newsroom, you might fare better against legal threats than a freelancer would. While everyone should be protected equally under the law, newsrooms often have resources like lawyers and money that they’ll use to defend you. When you’re not sure if something you’re doing could get you in trouble, consult a lawyer.

Sometimes sources pretend to be hacktivists or whistleblowers but are actually state-sponsored hackers. For instance, Russian military hackers posed as hacktivists when they compromised the Democratic Party and Hillary Clinton’s presidential campaign in 2016, interfering with the US election by sending hacked datasets to WikiLeaks. This sort of dataset might be authentic and newsworthy, but you don’t want to end up being a pawn in someone else’s information warfare. If you’re unsure about your source’s credibility or believe that they might have ulterior motives—or if you’re confident that they’re being dishonest with you—it’s important to mention your skepticism about your source, and why you have doubts, in your reporting. WikiLeaks did the opposite: It insisted its source wasn’t Russian intelligence when it knew otherwise, and it even spread the conspiracy theory that Seth Rich, a Democratic Party employee who was murdered, was the group’s real source, leading to years of harassment against Rich’s family members.

### Secure Storage for Datasets

As you prepare to receive a dataset from a source, the first thing to do is assess how sensitive you think that dataset is, since this will inform how you should go about protecting it, as well as how you will continue protecting your source. As mentioned, some datasets are completely public, while others are highly classified national security secrets, and others are somewhere in between. You might encounter a dataset with unique challenges that doesn’t fit this model, but in general there are three different sensitivities: low, medium, and high.

#### Low-Sensitivity Datasets

A dataset might be low-sensitivity if:

* It’s already completely public. This includes documents in response to a public records request or public datasets that anyone can download from a transparency collective like Distributed Denial of Secrets. (You’ll learn more about DDoSecrets in Chapter 2.)
* You believe that if law enforcement or an adversarial corporation gained access to the dataset, this wouldn’t lead to any retaliation against your source. 
* It doesn’t contain personal identifiable information, or PII, which I describe in detail in the “Redaction” section on page XX.


Basically, if you can’t think of any harm that would be caused if this dataset got shared more widely than you intended, including with law enforcement or leak investigators, then it’s probably low sensitivity.
It’s safe to work with low-sensitivity datasets in the cloud. By the cloud I mean other people’s computers: storage services like Google Drive, iCloud, Dropbox, hosting services like Amazon AWS, and any other service where anyone besides you and the people you’re working with will have access to the data. Cloud services are all vulnerable to legal requests, so if you’re investigating governments or corporations with powerful lawyers, they can send subpoenas to cloud providers to get data associated with your account. Additionally, the data you store in the cloud is only as safe as your account itself. You should make sure you have a strong password and turn on features like two-factor authentication to make your account significantly more difficult to hack.

### Medium-Sensitivity Datasets

Most datasets that aren’t low-sensitivity are medium-sensitivity. I think of a medium sensitive dataset as one that isn’t already public but that doesn’t require you going to extreme measures to secure it. For example, a dataset I’ll describe later in this chapter that includes medical records of hundreds of thousands of patients is medium sensitivity. These datasets should be stored on encrypted disks, disks that are locked in such a way that only the owner should be able to unlock them to access the data. This way if your laptop gets stolen, lost, or seized in a police raid, whoever gets it can’t access your files. If you haven’t already encrypted your disk, you’ll do so in Homework 1-3.

Medium-sensitivity data should also stay on your computer’s hard disk or a removable disk—avoid storing it in cloud services unless you have a good reason to do so, or if you’re able to store it encrypted in way that the cloud service can’t decrypt it. Storing datasets on local, encrypted disks,  greatly reduces the risk of anyone else gaining unauthorized access to them.

You can work with medium-sensitivity data on your typical work computer, as long as you secure your machine as follows:

* Make sure your computer’s hard disk is encrypted.
* Take other steps to protect your computer physically. Make sure the screen locks automatically after a short amount of inactivity and requires a password to unlock; promptly install software updates; and be wary of what programs you install and what documents you open on your computer. If you accidentally run malicious software, or open a malicious document, someone could hack your computer and gain access to your datasets.
* Storing dataset on an external USB disk allows you to store more data than will fit on your computer, and means you can travel with your laptop without worrying about protecting datasets stored on it. For any datasets you store in this way, make sure your disk is encrypted as well. You’ll learn to do this in “Disk Encryption” on page XX.
* Don’t store files in parts of your computer that get automatically uploaded to the cloud. For example, many Mac users have their computers configured to upload their Documents folder to iCloud, Apple’s cloud storage service. If your computer is set up this way, don’t put files related to these investigations in whatever folders upload to the cloud.

In general, you should work with medium-security data locally, meaning as files stored on your hard disk that aren’t exposed to any online services. There are cases where it’s reasonable to work with medium-security datasets remotely. If you’re working with other people, you may need to use an encrypted file sharing solution so that the service you’re using can’t decrypt the files, but you and your colleagues can. One simple option is to send files back and forth using the Signal messenger app, which, again, you’ll learn more about in Chapter 2. And if you or your organization are hosting a secure tool for searching datasets, such as Aleph, which is covered in Chapter 5, then it’s also reasonable to copy the data into that tool.

All of the datasets you’ll be working with in this book are low-sensitivity, since they’re all already public, but the techniques you’ll learn throughout the book will all be applicable for medium-sensitivity datasets as well: you’ll work with the data locally on your computer. While it’s fine to work with these particular datasets in the cloud, learning to work with them locally on your computer will give you the practice you need once you obtain more sensitive datasets.

### High-Sensitivity Datasets

High-sensitivity datasets are by far the most difficult to work with, for good reason. The Snowden Archive, for example, is high-sensitivity. I spent years reporting on this massive trove of secret government documents, which NSA whistleblower Edward Snowden gave to journalists, exposing US and allied spy agencies conducting warrantless surveillance and privacy invasions on an unimaginable scale. We didn’t want the FBI or NSA to gain access to it, which put cloud services out of the question, but more importantly, we didn’t want foreign intelligence services to access it either. We assumed that nation-state attackers had the capability to remotely hack pretty much any computer we used unless we took steps to make sure it never connected to any remote network. 

Going into detail on how to conduct high-sensitivity investigations is beyond the scope of this introductory book, and you won’t need these skills to work through future chapters. However, for future reference, this section outlines how you should proceed if you find yourself working with a cache of top-secret documents.

If a dataset is high-sensitivity, until you are close to publishing your report, you should store it or access it only using air-gapped computers, or computers that never connect to the internet. Move files off the air-gapped computer only when they are already redacted and necessary for publishing. In short, buy a new computer, never connect it to the internet, and use that. Or, if you have an old computer that would work, you can format its disk and reinstall the operating system, and use that computer while never connecting it to the internet. This will help you ensure that you’re starting from a clean system that doesn’t have any existing trackers or malware.  
For even more security, unscrew the computer’s case and physically remove the wireless hardware. You’ll run into all sorts of challenges related to moving data between your air-gapped computer and your normal work computer—for example, installing or updating software on your air-gapped computer requires downloading on another computer, carefully verifying that it’s legitimate software, and then transferring it to your air-gapped computer to install it. The extra steps are worth it, though, when a breach might have severe consequences.

It’s also important that the disk in your air-gapped computer and any USB disks that you use with it are encrypted with strong, random passphrases. Also consider the physical security of where you store your air-gapped computer and USB disks. If possible, store these in a safe or vault with a good lock. If you don’t have access to this, at least keep them in a locked room to which few people have keys. Always power off your air-gapped computer when you’re not using it—this makes it harder for attacks against the disk encryption to work.
While working on air-gapped computers, maintain an awareness of internet-connected electronic devices with microphones or cameras. Consider what conversations you’re having related to these highly sensitive documents within earshot of microphones, as well as whether any nearby cameras (including smartphones) could capture photographs of your screen.

### Authenticating Datasets

You can’t believe everything you read on the internet, and juicy documents or datasets that anonymous people send you are no exception. Disinformation is prevalent. It’s important to explain in your published report, at least briefly, what makes you confident in the data. If you can’t authenticate it but still want to publish your report in case it’s real, or in case others can authenticate it, you should make this clear. If in doubt, err on the side of transparency.
How you go about verifying that a dataset is authentic completely depends on what the data is. You have to approach the problem on a case-by-case basis. The best way to verify a dataset is to, if possible, use open source intelligence (OSINT), or publicly available information that anyone with enough skill can find. This might mean scouring social media accounts, consulting the Internet Archive’s Wayback Machine at https://web.archive.org, inspecting metadata of public images or documents, paying services for historical domain name registration data, or viewing any other types of public records. If your dataset includes a database taken from a website, for instance, you might be able to compare information in that database with publicly available information on the website itself to confirm that they match.

While this book references OSINT, I only focus on discussing how I’ve used it in my own investigations. If you want to learn more, one book I recommend is OSINT Techniques: Resources for Uncovering Online Information, by Michael Bazzell, along with the companion tools listed at https://inteltechniques.com/tools. This book describes a large number of tools and techniques for discovering details which might help you verify datasets using OSINT.

In this section, I’ll share two examples of authenticating data from my own experience: one about a dataset from the anti-vaccine group America’s Frontline Doctors, and another about leaked chat logs from a WikiLeaks Twitter group.

#### Authenticating the AFLDS Dataset

In late 2021, in the midst of the COVID-19 pandemic, an anonymous hacker sent me hundreds of thousands of patient and prescription records from telehealth companies working with America’s Frontline Doctors (AFLDS). AFLDS is a far-right anti-vaccine group that misleads people about COVID-19 vaccine safety and tricks patients into paying millions of dollars for drugs like ivermectin and hydroxychloroquine, which are ineffective at preventing or treating the virus. The group was initially formed to help Donald Trump’s 2020 reelection campaign, and the group’s former leader, Simone Gold, was arrested for storming the US Capitol on January 6, 2021. In 2022, she served two months in prison for her role in the attack.

My source told me that they got the data from the telehealth companies by writing a program that made thousands of web requests to a website run by one of the companies, Cadence Health. Each request returned data about a different patient. To see if that was true, I made an account on the Cadence Health website myself. Everything looked legitimate to me: the information I had about each of the 255,000 patients was the exact information I was asked to fill out when I created my account on the service, and various category names and IDs in the dataset matched what I could see on the website. But how could I be confident that the patient data itself was real, that these people weren’t just made up?

I wrote a simple Python script to loop through the 72,000 patients and put each of their email addresses in a text file. I then cross-referenced these emails with a totally separate dataset containing PII from members of Gab, a social network popular among fascists, anti-democracy activists, and anti-vaxxers. In early 2021, a hacktivist who went by the name “JaXpArO and My Little Anonymous Revival Project” had hacked Gab and made off with 65GB of data, including about 38,000 Gab users’ email addresses. Thinking there might be overlap between AFLDS and Gab users, I wrote another simple Python program that compared the emails from AFLDS with the emails from Gab and showed me all of the emails that were in both lists. There were several.

Armed with this information, I started scouring the public Gab timelines of those whose emails had appeared in both datasets, looking for posts about AFLDS. Using this technique, I found multiple AFLDS patients who posted about their experience on Gab, leading me to believe that the data was authentic. For example, according to consultation notes from the hacked dataset, one patient created an account on the telehealth site and four days later had a telehealth consultation. About a month after that, they posted to Gab saying, “Front line doctors finally came through with HCQ/Zinc delivery” (HCQ is an abbreviation for the drug hydroxychloroquine). 
Chapter 13 focuses entirely on my AFLDS investigation and describes the technical details of my Python script in greater depth. By the time you’ve worked through the intervening chapters, you’ll have the Python knowledge to understand how that script worked. 

#### Authenticating the WikiLeaks Twitter Group Chat

In late 2017, journalist Julie Ioffe published a revelation in The Atlantic: WikiLeaks had slid into Donald Trump, Jr.’s Twitter direct messages. Among other things, before the 2016 election, WikiLeaks suggested to Trump, Jr. that even if his father lost the election, he shouldn’t concede. “Hi Don,” the verified @WikiLeaks Twitter account wrote, “if your father ‘loses’ we think it is much more interesting if he DOES NOT conceed [sic] and spends time CHALLENGING the media and other types of rigging that occurred -- as he has implied that he might do.”

A long-term WikiLeaks volunteer who went by the pseudonym Hazelpress started a private Twitter group with WikiLeaks and its biggest supporters in mid-2015. After watching the group become more right-wing, conspiratorial, and unethical, and specifically after learning about WikiLeaks’ secret DMs with Trump, Jr., Hazelpress decided to blow the whistle on the whistleblowing group itself. She has since publicly come forward as Mary-Emma Holly, an artist who spent years as a volunteer legal researcher for WikiLeaks. 
To carry out the WikiLeaks leak, Holly logged into her Twitter account, made it private, unfollowed everyone, and deleted all of her tweets. She also deleted all of her DMs except for the private WikiLeaks Twitter group, and changed her Twitter username. Using the Firefox web browser, she then went to the DM conversation—which contained 11,000 messages and had been going on for two and a half years—and saw the latest messages in the group. She scrolled up, waited for Twitter to load more messages, and then scrolled up again, and kept doing this for four hours, until she reached the very first message in the group. She then used Firefox’s Save Page As function to save an HTML version of the web page, as well as a folder full of resources like images that were posted in the group.

Now that she had a local, offline copy of all messages in the DM group, Holly leaked it to the media. In early 2018, she sent a Signal message to the phone number listed on The Intercept’s tips page. At that time, I happened to be the one checking Signal for incoming tips. Using OnionShare—software that I developed for this purpose, which I describe in detail in Chapter 2—she sent me an encrypted and compressed file, along with the password to decrypt it. After extracting it, I found a 37MB HTML file—so big that it made my web browser unresponsive when I tried opening it, and which I would later split into separate files to make it easier to work with—and a folder with 82MB of resources.

How could I go about verifying the authenticity of a huge HTML file like this? If I could somehow access the same data directly from Twitter’s servers, that would do it—only an insider at Twitter would be in a position to create fake DMs that show up on Twitter’s website, and even that would be extremely challenging. When I explained this to Mary (who, at the time, I knew only as Hazelpress), she provided me with her Twitter username and password. She had already deleted all other information from that account. With my source’s consent and armed with her Twitter credentials, I logged in, went to her DMs, and found the Twitter group in question. It immediately looked like it contained the same messages as the HTML file, and I confirmed that the verified account @WikiLeaks frequently posted to the group.

This made me extremely confident in the authenticity of the dataset, but I decided to take verification one step further. Could I download a separate copy of the Twitter group myself so I could compare it with the version my source sent me? I searched around and found dmarchiver, a Python program that could do just that. Using this program, along with Mary’s username and password, I downloaded a text version of all of the DMs in the Twitter group. It took only a few minutes to run this tool, rather than four hours of scrolling up in a web browser. 
NOTE	After this investigation, the dmarchiver program stopped working due to changes on Twitter’s end, and today the project is abandoned. However, if you find yourself with a similar challenge in a future investigation, you could search for a tool that will work for you. You could also consider developing your own, using programming skills that you’ll learn in Chapters 7 and 8.

The output from dmarchiver, a 1.7MB text file, was much easier to work with compared to the enormous HTML file, and it also included exact timestamps. Here’s a snippet of the text version:

```
[2015-11-19 13:46:39] <WikiLeaks> We believe it would be much better for GOP to win.
[2015-11-19 13:47:28] <WikiLeaks> Dems+Media+liberals woudl then form a block to reign in their worst qualities.
[2015-11-19 13:48:22] <WikiLeaks> With Hillary in charge, GOP will be pushing for her worst qualities., dems+media+neoliberals will be mute.
[2015-11-19 13:50:18] <WikiLeaks> She's a bright, well connected, sadistic sociopath.
```

I could view the HTML version in a web browser, so that it looked exactly as it had originally looked on Twitter. This was also useful for taking screenshots to include in our final report, as shown in Figure 1-1.

[f02001.png]
<< a screenshot of the WikiLeaks DMs described above.>>

#### Figure 1-1 Screenshot of the leaked HTML file

Along with the talented reporter Cora Currier, I started the long process of reading all 11,000 chat messages, paying closest attention to the 10 percent of them from the @WikiLeaks account—which was presumably controlled by Julian Assange, WikiLeaks’ editor—and picking out everything in the public interest. We discovered that:

* Assange expressed a desire for Republicans to win the 2016 presidential election.
* Assange and his supporters were intensely focused on discrediting two Swedish women who had accused him of rape and molestation, as well as discrediting their lawyers. They spent weeks discussing ways to sabotage articles about Assange’s rape case that feminist journalists were writing.
* Assange tried to discredit filmmaker Laura Poitras because of how she portrayed him in Risk, the 2016 documentary about WikiLeaks. The film includes a scene in which Assange tells his lawyer that his accusers were part of a “thoroughly tawdry radical feminist political positioning thing,” and in another scene he says, “Part of the problem in this case is there’s two women, and the public just can’t even keep them separate. If there was one, you could go, ‘She’s a bad woman.’ I think that would have happened by now.”
* Assange used transphobic and misogynistic language when talking about Chelsea Manning, his source from 2010, and her friends. I discuss Manning’s relationship with WikiLeaks further in Chapter 2.
* After Associated Press journalist Raphael Satter wrote a story about harm caused when WikiLeaks publishes personal identifiable information, Assange called him a “rat” and said that, “he’s Jewish and engaged in the ((())) issue,” referring to an antisemitic neo-Nazi meme. He then told his supporters to “Bog him down. Get him to show his bias.”

You can our reporting on this dataset at https://theintercept.com/2018/02/14/julian-assange-wikileaks-election-clinton-trump. After The Intercept published this article, Assange and his supporters also targeted me personally with antisemitic abuse, and Russia Today, the state-run TV station, ran a segment about me. I discuss WikiLeaks and its history in greater depth in Chapter 2.

As you can see, the techniques you use to authenticate datasets vary greatly depending on the situation. Sometimes you can rely on OSINT, sometimes you can rely on help from your source, and sometimes you’ll need to come up with an entirely different technique.
Redaction

Once you’ve authenticated your dataset and are getting ready to publish the results of your investigation, you must consider whether or how you want to redact—that is, hide or delete—sensitive information. In some cases it might be safe to publish original documents without any redaction, and in other cases you might choose to not publish any documents at all. In this section I’ll discuss how you can think about these decisions, and the various reasons you might choose to redact, or not redact, information.

### Deciding What Data to Publish

When deciding how much data to redact, you’ll need to consider whether your method of reporting the revelations will enable leak investigators to uncover your source. For example, if a company’s human resources department sends an email to all of its 10,000 employees and one of them leaks the email to you, it will be very hard for the company to find the culprit, since it could be any of those 10,000 people. But if only 10 people have access to a document—or database logs show a list of 10 people who recently accessed it—the company has a real suspect list to work from.
Depending on how many people had access to the data that you’ve obtained, how sensitive it is, what your source is risking, and what they’re comfortable with, you should publish different types or quantities of data. Here are options for you to choose what data to publish, ordered from the most risk to your source to the least risk:
* Publish unaltered documents or datasets.
* Publish documents after you’ve redacted them and stripped them of metadata.
* Publish documents after recreating them from scratch, retyping them into new separate documents and publishing those instead. When you recreate documents, you remove any hidden trackers and make it impossible to tell just from the documents themselves if your source obtained them by photographing their screen, copying them to a USB stick, uploading them to a website, or using some other method.
* Not publish the documents at all, just describe and quote from them. 
* Not even quote from documents, just describe the revelations they contain. If leak investigators don’t know what documents were compromised, only that there’s an accurate news story that somehow reveals secret information, they’ll have a harder time making progress in their investigation.

Publishing documents is more transparent to your readers, and directly showing the evidence makes your work more credible, but this has to be weighed against protecting your source. You’ll have to make these decisions on a case-by-case basis, but you should always have the risks that your source faces at the top of your mind.

### Reasons to Redact

After you’ve carefully considered the risks to your source and you’ve made the decision to publish documents rather than just describing them, the next step is to decide what information in those documents to redact before publishing. There are three reasons to redact documents that you plan on publishing as part of your report: to continue protecting your source, to protect the privacy of others involved, or to protect government or corporate information that should justifiably remain secret.

### Protecting Your Source

If your dataset includes archives of a private website or databases that your source was logged into, you’ll want to redact their username or any other identifying information before publishing. It’s also important to make sure you don’t accidentally publish metadata that could reveal your source. There are many ways that this could happen, and this book won’t describe them all. To give two common examples, though, Word documents often include the name of the author, and photos often include GPS coordinates and the type of camera that was used. In 2012, John McAfee, the controversial millionaire software executive, was on the run. His home in Belize was raided by police and he fled the country. In a blog post, he wrote, “I am currently safe and in the company of two intrepid journalist from Vice Magazine [...]

We are not in Belize, but not quite out of the woods yet.” That day, Vice published their article about McAfee that included a photograph. According to the photo’s metadata, it was taken on an iPhone 4S and it included GPS coordinates to a specific house in Guatemala. By not stripping the photo of metadata, Vice had accidentally published his exact location. If they had simply taken a screenshot of that image and published the screenshot instead, they would have erased the metadata and kept the location secret.

In 2017, when President Donald Trump constantly called the accusations that Russia interfered in the US elections “fake news,” NSA whistleblower Reality Winner anonymously mailed a top secret document to The Intercept with evidence that NSA had, in fact, witnessed a Russian cyber attack against local election officials. The Intercept published the document, and a short time later Reality Winner was arrested. The published document included a type of metadata called printer dots, nearly invisible yellow dots that printers add to paper that include the serial number of the printer and the timestamp of when it was printed. While there’s no evidence that leak investigators even noticed these until after Reality Winner was arrested (she was one of six people who had printed this document, and the only one who had written an email to The Intercept), the printer dots could have outed her as well. The Intercept could have mitigated this by recreating the document, like by retyping it and recreating the artwork in it, and publishing that instead of a scanned version of the original.

### Protecting Personal Information in Datasets

Many datasets include names, email addresses, usernames, phone numbers, home address, passwords, and other similar Personal Identifiable Information (PII) of people who aren’t public figures. Many government and corporate documents include PII for random employees that, if you publish it, won’t add anything to your story, but could make these people targets of harassment. Even when dealing with public figures, in most cases it’s still responsible to redact their PII unless publishing it will add value to your report. For example, if the focus of your investigation is a lavish mansion owned by a billionaire, it might be reasonable to publish the address of that mansion. If you’re writing an unrelated story about that billionaire, however, there’s no reason to include their home address.
Even if you believe the targets of your investigation are jerks, it’s better to redact their PII if including it doesn’t add to your report. Even jerks have privacy rights, and needlessly publishing PII could be used to discredit your report regardless of the revelations it contains. When working with public datasets that contain lots of PII, you should still redact PII if it’s not an important part of the story. Anyone could find that PII themselves if they put in the effort, but there’s no need to draw attention to it.

The exception to this rule is if publicly outing someone is an important part of your story and could keep other people safe. For example, it’s ethical to name someone who is abusive in a workplace or industry, or to out someone as a member of a hate group. Even when you’re publicly outing someone, though, don’t publish unnecessary PII about them, like their home address. If you do so, you might get accused of harassment, which could completely distract the conversation from the wrongdoing that you’re trying to expose.

### Protecting Legitimate Secrets

Occasionally, governments and companies do in fact have legitimate reasons to keep secrets. In my experience, this is rare—the US government has a severe over-classification problem. This is one reason it’s important to ask related parties for comment before you publish your story, though: a government agency or company may give you information you didn’t know that could make you decide not to publicize the data. For example, I once helped make the decision to redact details from a top secret US government document related to another country’s nuclear weapons program.

### Making Requests for Comment

Always give the people or companies on which you’re reporting a chance to tell their side of the story. Even if you’re confident that they’re not going to respond to your request, or that they’ll respond with lies, you should still attempt to contact them, explain what you’re going to publish, and give them a chance to defend themselves. If they do respond, quote their response in your final published report (and if you know they aren’t telling the truth, explain that alongside their quote). If they don’t respond, or if they decline to comment, include that in your report as well.

For example, in 2017, I reported on leaked chat logs from neo-Nazis, which I cover in Chapter 14. In my article, I named a member of the pro-slavery hate group League of the South who was arrested during the deadly Charlottesville, VA Unite the Right protest for carrying a concealed handgun. He had posted messages in a chat room saying that he had “scores to settle” with local antifascists because they had gotten him fired from his job. Using public records, I tracked down a phone number for him. I set up a new virtual phone number using Google Voice and called him with that, since I didn’t want to give him my private number. I left messages, but he never responded.
If your investigation is adversarial—the people you’re looking into aren’t going to be happy with it—it’s always best to wait until shortly before you publish your report before contacting them and tipping your hand. It’s polite to give them at least 24 hours to respond. This gives them less time to sabotage your story: they might leak your story to a friendly publication to publish first with a positive spin, or announce to their followers that a hit piece is coming, or attempt to use legal means to stop you from publishing. I’ve been involved in investigations where all of these have happened.
Chances are, you’re not an expert in all aspects of what you’re reporting on. For this reason, it’s often a good idea to consult outside experts as well (university professors, authors, scientists, and so on) and include quotes from them in your published reports. In my own reporting, I’ve interviewed cryptography professors, disinformation researchers, medical doctors, and civil rights advocates who work for non-profits. Even if you are an expert on what you’re reporting on, providing outside voices often adds to your story, helping you make stronger arguments. 

As long as you trust the experts you’re talking with, it’s fine to contact them early in the reporting process. It’s also common to share confidential documents with them, so long as they agree to keep them secret until you publish. In the case of highly sensitive secret documents, you might need to arrange outside experts to visit you in person and view them on your air-gapped computer. Sometimes outside experts can also point you in research directions that you wouldn’t think to go yourself.

The first half of this chapter has focused on how to protect your sources and how to authenticate the information they give you. It’s time to move on to securing your own computer and online accounts, so you can keep the your datasets and other sensitive records safe. In the following sections, you’ll learn to use a password manager, encrypt disks, and protect yourself from malicious documents. 

### Password Managers

Most people’s passwords aren’t unique, meaning that they reuse the same password in multiple places. This is a very bad idea, since any duplicate password is only as secure as the least secure place you used it. Go to https://haveibeenpwned.com, search for your email address or phone number, and you’ll see a list of data breaches that you’re included in. If your LinkedIn password was exposed in a data breach a few years ago, but it’s the same password you use for your Twitter account, or to log into your laptop, or to unlock your encrypted USB disk full of sensitive datasets, you may be in trouble.
The solution to the problem of passwords is to make them all unique—never reuse the same password—and also make them strong, which really just means make them long enough and random—that is, impossible to predict. Unfortunately, strong passwords are hard to memorize, and it’s impossible for humans to memorize hundreds of passwords that are both strong and unique. Yet we’re required to use hundreds of passwords in our daily lives.

The solution is to let computers memorize most of your passwords for you. Password managers are programs that keep track of an encrypted database of passwords that you unlock using a master password, the only one you must memorize. Password managers often allow you to sync your password database to the cloud, which is fine so long as you’re using a strong master password. If a hacker steals your encrypted password database, or if your password manager company hands it to the FBI or other authorities, they won’t be able to unlock it without your master password. An encrypted password database is completely inaccessible to anyone without the master password. If your master password is strong, it will be literally impossible for them to guess it, and your other passwords will be safe. Encryption is cool like that.

### Donald Trump’s Twitter Password

I learned from an episode of the excellent podcast Darknet Diaries, hosted by Jack Rhysider, that Donald Trump’s LinkedIn password was exposed in a 2012 data breach. His password, yourefired, was his signature phrase from The Apprentice, the reality TV show he hosted. While he was running for president in 2016, three Dutch hackers, Victor, Edwin, and Matt, who are part of a group called the Guild of the Grumpy Old Hackers, discovered his LinkedIn password in the dataset from that breach. They tried it on Trump’s @realDonaldTrump Twitter account and . . . it worked.

You might be thinking, “Isn’t using a password manager just putting all my eggs in one basket? If it gets hacked, doesn’t that give the hacker access to everything?” This is true—it’s very important to secure your password manager—but not using one at all is like trying to hold hundreds of eggs with just your hands, without using a basket, and without breaking any of them. If you try that, you’re bound to drop a lot of your eggs eventually. You also always have the choice of using multiple password managers (multiple baskets) for different projects, so that if one gets hacked, the others remain secure. I myself use separate managers for personal passwords and work passwords.
In the following homework assignment you’ll set up a password manager of your own. Using a password manager is a critical part of maintaining your own digital security, which by extension will help you protect your sources. 

#### Homework 1-1: Start Using a Password Manager
Several good password managers exist, and if you already know of one you like, by all means use it. Here are the three that I recommend:

#### Bitwarden
This manager is free and open source, and it will sync passwords between your computers and phone. It has browser extensions to automatically fill in your passwords when logging into websites. It's a good choice for a day-to-day password manager. You can download it at https://bitwarden.com.

#### 1Password
Like Bitwarden, 1Password will sync passwords between your computer and phone and has a browser extension. It’s also a good choice for a day-to-day password manager. It costs money, but 1Password gives free licenses to journalists. You can download it at https://1password.com, or see https://1password.com/for-journalism for more information about the free license program.

#### KeePassXC
This software is great for high-security situations. Unlike Bitwarden and 1Password, KeePassXC doesn’t sync your encrypted password database to the cloud, which makes it less convenient but also potentially more secure. It works well on air-gapped computers. You can download it at https://keepasscx.org.

If you’d like to use Bitwarden, 1Password, or a similar password manager that syncs between devices, install it on your computer, your phone, and as an extension in your web browser now, following the installation instructions on your password manager’s website. If you’re using a local-only password manager like KeePassXC, just install it on your computer.

When you first set up your password manager, it’s extremely important that you not forget your master password. Unlike most website passwords, there’s no way to “reset” a master password. If you forget it, you’re locked out of your password manager forever and you lose all the rest of your passwords. I recommend writing the master password down on a piece of paper until you’re sure that you’ve memorized it, and then destroying the paper.

The best master passwords are passphrases, a sequences of words picked at random from a dictionary. They’re also easier to remember than completely random passwords. An example of a good passphrase is movie-flanked-census6-casino-change. It has no meaning at all, but with practice it’s not too hard to memorize.

Once you’ve set up your password manager account, add your other passwords to the manager. Start by adding the passwords you use the most: perhaps your email password, or passwords to social media accounts. If you’ve ever re-used these passwords, take this opportunity to change your passwords and make them better. Whenever you create a new password, use your password manager’s password generator. This is a tool that’s included in password managers that helps you create strong passwords. Typically, password generators have settings that let you choose if it should generate a password or a passphrase, if it should contain numbers or special characters, how long it should be, and so on. 

Bitwarden, for example, can create both passwords or passphrases. Figure 1-2 shows a screenshot from Bitwarden’s password generator, which is configured to create a passphrase with five words, separated by dashes, capitalizing the words, and that includes a number.

[f02005.png] 
<<Screenshot showing BitWarden’s password generator. It’s generating a strong passphrase with 5 random words, separated by dashes, capitalizing letters, and including a number: Passover-Widely-Unnamable9-Underrate-Degrease>>

#### Figure 1-2 BitWarden’s password generator
Bitwarden can also make strong passwords such as Frz6ioX4o@cCY. All your passwords should either be strong passphrases or passwords like these.

The password generators that are included in 1Password, KeePassXC, and other password managers all include similar features. While Bitwarden allows you to open the password generator tool independently, some password managers require you to add a new item in your password database, or edit an existing item, to access the password generator.
When you need to come up with a new password, it doesn’t matter if you choose to use a password or a passphrase so long as it’s strong and unique. However, passphrases tend to be easier to memorize and also easier to type. For this reason, I tend to use passwords to login to websites (I don’t need to type them, my password manager fills them in for me) and passphrases for anything that I might need to memorize or type, such as a disk encryption passphrase, or the passphrase to login to my computer.

Every time you create a new account, or log into an existing account, add the password to your password manager. Now that you you have a safe place to keep track of your passwords, such as passphrases used to encrypt hard disks—you’ll generate one of these in Homework 1-2—it’s time to move on to the next practical step you can take to protect your sources and yourself: disk encryption.

### Disk Encryption

Disk encryption allows you to protect your data from people who have physical access to your phone, laptop, or USB disk. It prevents anyone from accessing data on a device if you lose it, someone steals it, it gets confiscated at a border crossing or checkpoint, or your home or office is raided. For example, when the internal disk in your laptop isn’t encrypted, anyone with physical access to it can unscrew your laptop’s case, remove the disk, and plug it into their own computer, accessing all of the data without needing to know any of your passwords. But when your disk is encrypted, all of this data is completely inaccessible to anyone who doesn’t have the right key. If disk encryption is enabled, they’ll need to first unlock the disk, typically using a password, a PIN, or biometrics like a fingerprint or face scan. You’ll learn how to encrypt your internal disk and a USB disk in the following homework assignments.

While disk encryption is an important part of protecting your data, it doesn’t protect against remote attacks. For example, if your laptop is encrypted but someone tricks you into opening a malicious Word document that attacks your computer, disk encryption won’t stop them from accessing your files. Disk encryption also won’t help much if the attackers get access to your device while it’s unlocked—for example, if you step away from your laptop at a coffee shop without locking your screen, or if attackers can easily unlock your phone by forcing you to use biometrics. For example, after arresting you, a cop might wave your phone in front of your face to unlock it with a face scan. 
You, of course, won’t be relying on disk encryption to commit crimes, but here’s a story of someone who was, and how it failed them. Even though the laptop that Ross Ulbricht, the creator of the darknet market website Silk Road, used disk encryption, the FBI still accessed all of his data by getting to it while the screen was unlocked. In 2013, Ulbricht was using his laptop at the San Francisco Public Library when two undercover FBI agents distracted him by pretending to be lovers in a fight. Making sure his screen was unlocked, they quickly arrested him, then copied important files off of his computer. If his screen had locked, and he’d had a strong password, disk encryption might have prevented them from accessing his data at all. Ulbricht was charged with money laundering, hacking, drug trafficking, and other crimes.

Encrypting your laptop’s internal disk is a basic security measure that everyone should take. It’s quick and easy to set up, it doesn’t require you to do any extra work on a regular basis, and it protects your privacy if you lose your device. You can think of it like wearing a seatbelt: there’s really no good reason not to do it. Encrypting your laptop’s internal disk is especially important if you’re going to be working with sensitive data. If you haven’t already encrypted it, you’ll do so in the next homework assignment.

#### Homework 1-2: Encrypt Your Internal Disk 

This assignment shows you how to encrypt the internal disk in your computer, whether you have a Windows, Mac, or Linux machine. Skip to the appropriate section for your OS.

#### Encrypting a Windows Disk

Different versions of Windows and different PCs have support for different types of disk encryption. Pro editions of Windows include BitLocker, Microsoft’s disk encryption technology, and Home editions include device encryption, which is basically Bitlocker with limited features. These features work only if your PC is new enough, though. If your computer came with at least Windows 10 when it was new, it should support disk encryption, but if it came with an earlier version of Windows, it might not. I go over options for how to proceed in this case at the end of this section.

#### BitLocker

To find out whether your computer includes BitLocker, click the Start button (the Windows icon in the bottom-left of your computer), search for bitlocker, and open Manage BitLocker. If your version of Windows supports it, the window should show whether BitLocker is enabled on your C: system drive, and you should have the option to enable it. If so, do that now.

When you enable BitLocker, it will make you save a recovery key to either your Microsoft account, a file on a non-encrypted USB disk, or a printed document. Saving your recovery key to your Microsoft account is the simplest option, but it does mean that Microsoft, or anyone with access to your Microsoft account, can access to the key needed to unlock your disk. If you’d prefer to not give Microsoft this access, I recommend printing the recovery key. You should also save your key in your password manager. If your computer breaks, you’ll need your recovery key to access any of your data on your encrypted disk.

#### Device Encryption

If your version of Windows doesn’t include BitLocker, try device encryption. Click Start, then navigate to Settings4Update & Security (or Privacy & Security, depending on your Windows version). Then go to the Device encryption tab to see if it’s enabled, and to enable it. 
If you see no Device encryption tab, your PC doesn’t support device encryption, unfortunately. You have a few options at this point. You could upgrade to the Pro version of Windows, which typically costs about $100, and then use BitLocker (this is the easiest option). Alternatively, you can use open source software called VeraCrypt.

#### VeraCrypt

VeraCrypt is free and open source disk encryption software. I go into further detail about it later in the chapter too. To begin, download VeraCrypt from https://veracrypt.fr, install it on your computer, and open it.

Click Create Volume to open the VeraCrypt Volume Creation Wizard. On the first page of the wizard, VeraCrypt lets you choose between three types of encrypted volumes. Select Encrypt the system partition or entire system drive, and click Next.

On the Type of System Encryption page, choose Normal and click Next. On the Area to Encrypt page, choose Encrypt the Windows system partition and click Next. On the Number of Operating Systems page, choose Single-boot and click Next (unless you have multiple OSes on your computer, in which case choose Multi-boot). On the Encryption Options page, use the default settings and click Next.

The next page is the Password page. You’ll need to come up with a strong passphrase that you’ll have to enter each time you boot up Windows. If that password is weak, your disk encryption will be weak, so be sure the password is strong. I recommend generating a strong passphrase and saving it in your password manager—this way, if you forget it the next time you reboot your computer, you can look it up on your password manager on your phone. Type the passphrase twice and click Next.

The next page is called Collecting Random Data. VeraCrypt includes a feature where you move your mouse around the window as randomly as you can, using the information it collects from your mouse movements to make the encryption more secure. Move your mouse around until the bar at the bottom of the screen is green, and then click Next. Click Next again on the Keys Generated page.

The Rescue Disk page prompts you to create a VeraCrypt Rescue Disk, which you can use in the case that your disk gets damaged and have issues booting Windows. Creating a rescue disk is outside the scope of this book though, so check Skip Rescue Disk verification and click Next. On the Rescue Disk Created page, click Next again.
On the Wipe Mode page, select None (fastest) as the Wipe mode and click Next. On the System Encryption Pretest page, click Test to test that disk encryption will work properly on your computer—this will reboot your computer, and you’ll need to type your VeraCrypt passphrase to boot up.

When you reboot your computer it should boot up to the VeraCrypt Boot Loader, and you’ll need to type the VeraCrypt passphrase to proceed. Under PIM, just press ENTER. If all goes well, it will succeed, Windows will boot up, and VeraCrypt will open on the Pretest Completed again after you login. Click the Encrypt button to begin encrypting your internal disk with VeraCrypt. From now on, you’ll need to type your VeraCrypt passphrase each time you boot your computer, but all of your data will also be protected with this passphrase.

#### Encrypting a Mac Disk

Apple’s disk encryption technology is called FileVault. If you’re using macOS Ventura or newer, open the System Settings app, click Privacy & Security on the left, and scroll down to the FileVault section. (If you’re using a version of macOS older than Ventura, open the System Preferences app, click Security & Privacy, and make sure you’re on the FileVault tab.) If FileVault is turned off, turn it on.
The password that unlocks your Mac’s disk is the password you use to log into your account. If that password is weak, your disk encryption is weak, so be sure your Mac password is strong.

When you enable FileVault, it will make you save a recovery key. Save that key in your password manager. If you forget your Mac password, you’ll need the recovery key to access any of your data. If you’re using a local password manager that doesn’t sync to the cloud, like KeePassXC, then store a copy of your recovery key somewhere else as well, such as on a piece of paper that keep in a secure location.

#### Encrypting a Linux Disk

Linux uses technology called LUKS for disk encryption. You can check the Disks program (in most versions of Linux, you can open this program by pressing the Windows key, typing “disks,” and pressing ENTER) to see whether your internal disk is encrypted. As shown in Figure 1-3, the program shows you all of the disks attached to your computer and allows you to format them. If your internal disk has an unlocked partition with LUKS encryption, as shown in the figure, disk encryption is enabled.

[f02004.png]
<< A screenshot of the Disks app in Linux >>

#### Figure 1-3 Managing disks and partitions using Disks in Linux
In this case, my internal disk is the 500GB Samsung SSD listed on the left. My disk is partitioned into four parts, and the last part (Partition 4) is 499GB big and is encrypted with LUKS. Your disk might like different than mine, but you’ll know it’s encrypted if the main partition says LUKS.

Unfortunately, you can’t just turn LUKS on or off. If your disk isn’t encrypted, the only way to encrypt it is to reinstall Linux, this time making sure to encrypt the disk. When you’re installing Linux, one of the first steps in the installation process will be to partition your disk; make sure to enable encryption during this step. If you’re going to reinstall Linux, make sure to back up your data. When choosing your encryption passphrase, save a copy of this in your password manager; you’ll need it every time you boot up your computer.

#### Homework 1-3: Encrypt a USB Disk

Your internal disk alone likely isn’t large enough to store all of the datasets you’ll need to work with. In order to do all of the homework in this book and work with the massive datasets in later chapters, you’ll need a USB disk that’s at least one terabyte big. To encrypt that USB disk, you’ll also need to format it, which will delete any data already on it. This homework shows how to do that for whichever OS you’re using.

Before you jump in and get started, here’s some background on how mass storage devices (like hard disks, SD cards, and so on) work. Storage devices are typically split one or more partitions, also called volumes, with each partition using a format called a filesystem. You can think of partitions as cabinets that use different shelving systems (filesystems) to organize data. Different OSes use different filesystems. Windows often uses a filesystem called NTFS, macOS often uses APFS, and Linux often uses ext4. There are also filesystems that all three OSes are able to use, such as ExFAT. 

When you erase a storage device, you delete all of the partitions on it so that the whole device contains unallocated space. You can then create a new partition—with USB disks, you’ll typically create a single partition that takes up all of the unallocated space—and format it using the filesystem that matches your OS.

Whether you’re working in Windows, macOS, or Linux, begin by plugging your USB disk into your computer. Open your password manager and save a new strong passphrase, created using your password manager’s password generator. Name the password something like datasets USB disk encryption. 

To begin encrypting your disk, skip to the appropriate subsection for your OS. If you’re a Windows user who doesn’t have BitLocker, skip to the section for encrypting USB disks with VeraCrypt, an open source disk encryption software.

**NOTE**
VeraCrypt also comes in handy if you need to access the same encrypted disk across operating systems—for example, if you need to use it on both a Windows PC and a Mac. However, for the purposes of this book, only Windows users who don’t have BitLocker should use VeraCrypt. In general, you’ll have fewer headaches if you stick with the disk encryption software built into your OS.

#### Encrypting USB Disks in Windows with BitLocker

If you have a Windows computer with BitLocker, use that to encrypt your USB. First, make sure to format the USB disk as NTFS. To do so, click the Start button, search for disk management, and open Create and format hard disk partitions. This opens the Windows Disk Management app, as shown in Figure 1-4, which show you all of the disks connected to the PC and lets you format them. 

[f02006.png]
<<Screenshot of the Disk Management app in Windows.>>

#### Figure 1-4 Screenshot of the Disk Management app in Windows
The bottom part of the window in the screenshot shows each disk attached to your computer and how they’re separated into partitions. Disk 0 is my internal hard disk (as you can see, one of the partitions is C:), and Disk 1 is a USB disk (one of those partitions is D:). On my computer, Disk 1 has a single 32GB partition, as well as about 86GB of unallocated space.

Find the USB disk you need to format. Right-click on every partition and choose Delete Volume until you’ve deleted all the partitions on the disk. Then right-click on the unallocated space in your disk and choose New Simple Volume. This should open a wizard to help you create the volume. Choose the full amount of disk space, and format it as NTFS. The wizard will ask you for a volume label, which is just a name for your partition—in Figure 1-4, the label for D: is data. I recommend calling this disk datasets.

Once the disk is formatted, click the Start button, search for bitlocker, and open Manage BitLocker. You should now see your USB disk and have the option to turn on BitLocker. When you enable BitLocker on your USB disk, a window should pop up asking how you would like to unlock this drive. Choose Use a password to unlock the drive, then copy and paste the USB disk encryption passphrase that you created at the beginning of this homework assignment from your password manager into the password field. You’ll need to paste it into field to retype the password as well. When you enable BitLocker, you will be required to save a recovery key by saving it to a file. Though since you’re saving the passphrase in a password manager, you don’t need your recovery key, and you can delete it.

#### Encrypting the USB Disk in Windows with VeraCrypt

If you use Windows Home and don’t have BitLocker available on your computer, you can use VeraCrypt to encrypt your USB disk. 
If you don’t already have VeraCrypt, download it from https://veracrypt.fr, install it on your computer, and open it. Click Create Volume to open the VeraCrypt Volume Creation Wizard. On the first page of the wizard, VeraCrypt lets you choose between three types of encrypted volumes. Select Encrypt a non-system partition/drive and click Next.
On the Volume Type page, VeraCrypt will ask if you want a standard volume or a hidden one. Select Standard VeraCrypt volume and click Next. On the Volume Location page, click the Select Device button, choose the USB disk you want to encrypt, and click Next. On the Volume Creation Mode page, select Create encrypted volume and format it and click Next. On the Encryption Options page, use the default settings and click Next. You can’t do anything on the Volume Size page, since you’re encrypting a while partition rather than creating an encrypted file container, so just click Next.

On the Volume Password page, copy and paste the USB disk encryption passphrase that you created at the beginning of this homework assignment from your password manager into the Password field, and paste it again into the Confirm field. Then click Next. On the Large Files page, VeraCrypt asks if you intend to store files larger than 4GB in your VeraCrypt volume. Select Yes and click Next. On the Volume Format page, under the Filesystem dropdown select exFAT, and check the box next to Quick Format. VeraCrypt also includes a feature where you move your mouse around the window as randomly as you can, using the information it collects from your mouse movements to make the encryption more secure. Move your mouse around until the bar at the bottom of the screen is green, and then click Format.
A window should pop up, warning you that all of the data on your USB disk will be erased and asking if you’re sure you want to proceed. Click Yes, and then wait while VeraCrypt creates an encrypted partition on your USB disk. As long as you selected Quick Format on the previous page, this should only take a few seconds. On the Volume Created page, click Exit to exit the wizard and get back to the main VeraCrypt window.

After you encrypt a USB disk with VeraCrypt, you need to use VeraCrypt to mount it, which means make it available on your computer as a drive letter. In the main VeraCrypt window, select an available drive letter (such as F:), click the Select Device button, select your VeraCrypt-encrypted USB disk, and click OK, then Mount. After you provide the encryption passphrase to unlock it, VeraCrypt will mount your encrypted USB disk so you can use it. Now any files that you save to this drive will be stored encrypted on disk. 
Before unplugging your USB disk you should unmount it. To unmount a disk, select the drive letter in VeraCrypt and click the Dismount button.

#### Encrypting USB Disks with macOS

If you’re using a Mac, open the app called Disk Utility, which you can find in the Applications4Utilities folder. This app shows you all of the disks attached to your computer and lets you format them.
In Disk Utility, select the USB disk you plugged in and click the Erase button. Give the disk the name datasets and choose APFS (Encrypted) for format. You will then be prompted for the password to unlock the encrypted disk. Copy and paste the USB disk encryption passphrase that you created at the beginning of this homework assignment from your password manager into Disk Utility. Disk Utility will also prompt you for a password hint, but because you’re saving this passphrase in your password manager and not bothering to memorize it anyway, leave the password hint blank.

#### Encrypting USBs with Linux

If you’re using Linux, open the Disks app as you did in Homework 1-2. Select your USB disk in the list of disks on the left, then click the menu button and choose Format Disk. This will delete all of the data on the USB.

Click the + button to add a new partition and set the partition size to the largest option. Give your disk the name datasets, choose Internal disk for use with Linux systems only, and check the box Password protect volume (LUKS). It will prompt you to enter a password. Copy and paste the USB disk encryption passphrase that you created at the beginning of this homework assignment from your password manager into Disks.

#### Protecting Yourself from Malicious Documents

You now have an encrypted USB disk on which to store your datasets. Before you start working with those datasets, though, you should know how to protect yourself from potentially malicious documents they contain. 

Have you ever been told to avoid opening email attachments from unknown senders? This is solid computer security advice, but unfortunately for researchers, journalists, activists, and many other people, it’s impossible to follow. In these lines of work, it’s often your job to open documents from strangers, including leaked or hacked datasets.

Opening documents that you don’t trust is dangerous because it may allow others to hack your computer. PDFs and Microsoft Office or LibreOffice documents are incredibly complex. They can be made to automatically load an image from a remote server, tracking when a document is opened and from what IP address. They can contain JavaScript or macros that, depending on how your software is configured, could automatically execute code when opened, potentially taking over your computer. And like all software, the programs you use to open documents, like Microsoft Office and Adobe Reader, have bugs, and these bugs can sometimes be exploited to take over your computer.
This is exactly what Russian military intelligence did during the 2016 US election, for example. First, the Main Directorate of the General Staff of the Armed Forces of the Russian Federation (GRU) hacked a US election vendor known as VR Systems and got its client list of election workers in swing states. It then sent 122 emails to VR Systems’ clients from the email address vrelections@gmail.com, with the attachment New EViD User Guides.docm. If any of the election workers who got this email opened the attachment using a vulnerable version of Microsoft Word in Windows, the malware would have created a backdoor into their computer for the Russian hackers. 
Sending malicious emails to specific targets in this way as part of a hacking operation is called spearphishing. Figure 1-5 shows a screenshot of one of the spearphishing emails targeting an election worker in North Carolina, which The Intercept obtained using a public records request. We don’t know for sure if any of the targets opened the malicious attachment.

[f02011.png]
<<This spearphishing email is disguised as an email from VR Systems Inc. It says, “Please take a look at the instructions for our modernised products,” and includes a malicious attachment.>>

#### Figure 1-5 Screenshot of the spearphishing email
In 2017, Reality Winner leaked a classified document describing this spearphishing attack to The Intercept. Thanks to her whistleblowing, the public knows considerably more about Russia’s attacks on the US election in 2016 than they otherwise would. In fact, US states like North Carolina only learned that they were under attack by Russian hackers by reading The Intercept. In 2022, two former election officials told 60 Minutes that Reality Winner’s disclosure helped secure the 2018 midterm elections against similar hacking attempts.
To make it safer to open documents you don’t trust, I developed an open source app called Dangerzone. When you open an untrusted document in Dangerzone, the app converts it into a known-safe PDF—one that you can be confident is safe. Using technology called Linux containers—which are like quick, small, self-contained Linux computers running inside your normal computer—it converts the original document into a PDF if it’s not already one, splits the PDF into different pages, and converts each page into raw pixel data. Then in another Linux container, it converts the pixel data back into a PDF. You can also ask it to use optical character recognition (OCR) technology, software that looks at an image of text and figures out what the characters are, to add a text layer back to the PDF so you can still search the text.

Dangerzone is essentially the digital equivalent of printing out a document and rescanning it. This will strip anything malicious from it, and also remove the original document’s digital metadata. If you opened the malicious New EViD User Guides.docm document using Dangerzone, it would create a new document called New EViD User Guides-safe.pdf. You could then safely open this PDF without risking your computer getting hacked. As an added benefit, you don’t need internet access to use Dangerzone, so it works well on air-gapped computers.

You’ll learn more about Dangerzone and Linux containers in Chapter 5, which covers how to make datasets searchable. First, though, in the following homework assignment, you’ll install it on your computer and practice using it.

#### Homework 1-4: Play with Dangerzone

For this homework, you’ll install Dangerzone and use it to convert documents into known-safe versions. Figure 1-6 shows a screenshot of Dangerzone in action, in this case converting the untrusted document D&D 5e - Players Handbook.pdf to a known-safe version called D&D 5e - Players Handbook-safe.pdf, which is also OCR’d and searchable.

[f02012.png]
<<A screenshot of Dangerzone converting a PDF into a known-safe version of it. The interface says, “Converting page 18/293 from pixels to searchable PDF.”>>

#### Figure 1-6 Dangerzone in action
You can download and install Dangerzone at https://dangerzone.rocks. Dangerzone relies on Linux containers. If you’re working on a Windows or macOS machine, the easiest way to get containers running is to use software called Docker Desktop. When you open Dangerzone for the first time, it will prompt you to install Docker Desktop. You’ll learn more about Docker in Chapter 5.
Now that Dangerzone is installed, try it out. Open any PDF, Microsoft Office document, LibreOffice document, or image on your computer in Dangerzone and convert it to a safe PDF. If someone attaches a document to an email and you don’t trust it, download a copy of it first, open Dangerzone, and click the Select suspicious documents button. Then browse for the document you downloaded, and use Dangerzone to convert it into a known-safe version.

#### Virtual Machines

Another option, which is a bit more complicated, is setting up a virtual machine (VM). VMs are like a stronger version of Linux containers. They isolate the software running inside the VM more than Linux containers can, and they can run any operating system. If you do this, make sure to disable internet access in your VM before opening documents. This way, if the document is malicious, it won’t let any attackers know the document was opened.

Giving detailed instructions on using VMs is outside the scope of this book. However, if you want to try them out on your own, the easiest way to get started is to use the free and open source virtualization software VirtualBox (https://www.virtualbox.org). VirtualBox works for Intel-based Macs, Linux, and Windows computers. If you have an Apple Silicon Mac, you can use Paralells (https://www.parallels.com) or VMware Fusion (https://www.vmware.com/products/fusion.html). Both Parallels and VMware Fusion cost money.

Dangerzone works great with PDFs and Word documents, but not so great with spreadsheets. This is because no matter what type of file you open in Dangerzone, you always end up with a safe PDF, and spreadsheets really aren’t meant to be read in PDF form. If Dangerzone doesn’t do a good enough job with a document you’d like to read, there are a few other ways you can open it while containing the damage. If you don’t believe the document is sensitive, you could upload it to Google Drive and then open it there, using Google’s web interface. This way, technically Google is opening the malicious document on its computers instead of you opening it on yours.

